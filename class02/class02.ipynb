{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmJbDTtRXLlvqGPiXK1yLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThousandAI/Application-of-AI/blob/main/class02/class02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd"
      ],
      "metadata": {
        "id": "Ponpy9Ux62G3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "q7i3nHPM64UO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grad = True\n",
        "tensor = torch.rand(3, requires_grad=True)\n",
        "print(tensor)\n",
        "y = tensor + 6\n",
        "print(y)\n",
        "z = 3*y**2 + 2\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "z.backward() # dz/d(tensor)\n",
        "print(tensor.grad) # 2*tensor + 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBe9qmCGEggA",
        "outputId": "75d587e4-b277-44eb-98ac-aec2ee0e8e8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4864, 0.1889, 0.0112], requires_grad=True)\n",
            "tensor([6.4864, 6.1889, 6.0112], grad_fn=<AddBackward0>)\n",
            "tensor([128.2195, 116.9068, 110.4040], grad_fn=<AddBackward0>)\n",
            "tensor(118.5101, grad_fn=<MeanBackward0>)\n",
            "tensor([12.9728, 12.3778, 12.0224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grad = False\n",
        "tensor = torch.rand(3, requires_grad=False)\n",
        "print(tensor)\n",
        "\n",
        "y = tensor + 6\n",
        "print(y)\n",
        "z = 3*y**2 + 2\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "z.backward() # dz/d(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "DVqioIEdGVZ1",
        "outputId": "5cccc312-9cc8-440b-e81f-1796c8eb9b08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9621, 0.2801, 0.9149])\n",
            "tensor([6.9621, 6.2801, 6.9149])\n",
            "tensor([147.4122, 120.3188, 145.4484])\n",
            "tensor(137.7265)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-563e730d457a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dz/d(tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not scalar\n",
        "tensor = torch.tensor([0.37, 0.58, 0.33], requires_grad=True)\n",
        "print(tensor)\n",
        "\n",
        "y = tensor + 6\n",
        "print(y)\n",
        "z = 3*y**2 + 2\n",
        "print(z)\n",
        "z.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "l6FD4WGtIT9U",
        "outputId": "9b32f4c6-9b34-480d-ee3d-9516ae3c8444"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3700, 0.5800, 0.3300], requires_grad=True)\n",
            "tensor([6.3700, 6.5800, 6.3300], grad_fn=<AddBackward0>)\n",
            "tensor([123.7307, 131.8892, 122.2067], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5a0ee7f37a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grad \n",
        "tensor = torch.rand(3, requires_grad = True)\n",
        "print(tensor)\n",
        "y = tensor.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2PI4_woMZZH",
        "outputId": "d3b156b2-60c8-4470-a023-7b3bb4e038f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7450, 0.4478, 0.1480], requires_grad=True)\n",
            "tensor([0.7450, 0.4478, 0.1480])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grad \n",
        "with torch.no_grad():\n",
        "  y = tensor + 2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzTe8mWHNcrN",
        "outputId": "4f8827b1-35b5-4c7d-d2da-85df614a89b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.7110, 2.0037, 2.2208])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accumulated gradient\n",
        "weights = torch.tensor([2., 3., 5., 7.], requires_grad=True)\n",
        "\n",
        "for epoch in range(5):\n",
        "  outputs = (3*weights).sum()\n",
        "  outputs.backward()\n",
        "\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoH6LzDgNn_y",
        "outputId": "996712c6-4b86-46ec-a231-76f638041d62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n",
            "tensor([12., 12., 12., 12.])\n",
            "tensor([15., 15., 15., 15.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# empty gradient\n",
        "weights = torch.tensor([2., 3., 5., 7.], requires_grad=True)\n",
        "\n",
        "for epoch in range(5):\n",
        "  outputs = (3*weights).sum()\n",
        "  outputs.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mtfoD9uOM8l",
        "outputId": "73d4390b-3e25-4876-c08a-014f19c2c3dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## toy example"
      ],
      "metadata": {
        "id": "fZ8DMG-0hFuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example\n",
        "x = torch.tensor([[1,-1], [2,3], [5,2]], dtype=torch.float32) # 3x2\n",
        "y = torch.tensor([[1],[0],[1]], dtype=torch.float32)\n",
        "\n",
        "w1 = torch.rand(2,3, requires_grad=True)\n",
        "w2 = torch.rand(3,3, requires_grad=True)\n",
        "w3 = torch.rand(3,2, requires_grad=True)\n",
        "w4 = torch.rand(2,1, requires_grad=True)\n",
        "relu = nn.ReLU()\n",
        "sigmoid = nn.Sigmoid()\n",
        "bce = nn.BCELoss()\n",
        "\n",
        "def forward(inputs):\n",
        "    inputs = torch.matmul(inputs, w1)\n",
        "    inputs = relu(inputs)\n",
        "    inputs = torch.matmul(inputs, w2)\n",
        "    inputs = relu(inputs)\n",
        "    inputs = torch.matmul(inputs, w3)\n",
        "    inputs = relu(inputs)\n",
        "    inputs = torch.matmul(inputs, w4)\n",
        "    outputs = sigmoid(inputs)\n",
        "    return outputs\n",
        "\n",
        "# loss\n",
        "def loss(y_true, y_pred):\n",
        "    return bce(y_pred, y_true)\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # forward pass\n",
        "    y_hat = forward(inputs=x)\n",
        "\n",
        "    # loss\n",
        "    bce_loss = loss(y_true=y, y_pred=y_hat)\n",
        "\n",
        "    # backward loss\n",
        "    bce_loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "        w3 -= learning_rate * w3.grad\n",
        "        w4 -= learning_rate * w4.grad\n",
        "\n",
        "    # zero gradients\n",
        "    w1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    w3.grad.zero_()\n",
        "    w4.grad.zero_()\n",
        "\n",
        "    \n",
        "    print(f\"epoch {epoch + 1}: \\nw1 = {w1}\\n w2 = {w2}\\n w3 = {w3}\\n w4 = {w4}, loss = {bce_loss:.8f}\")"
      ],
      "metadata": {
        "id": "FLCYuNb3j10E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ea499a-b99a-4182-918b-905c9f412656"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: \n",
            "w1 = tensor([[0.1328, 0.5382, 0.5504],\n",
            "        [0.1804, 0.2279, 0.2337]], requires_grad=True)\n",
            " w2 = tensor([[0.2289, 0.5638, 0.1632],\n",
            "        [0.3929, 0.2375, 0.9889],\n",
            "        [0.4418, 0.8465, 0.7737]], requires_grad=True)\n",
            " w3 = tensor([[0.8405, 0.9692],\n",
            "        [0.5840, 0.0423],\n",
            "        [0.6044, 0.0615]], requires_grad=True)\n",
            " w4 = tensor([[0.7141],\n",
            "        [0.8803]], requires_grad=True), loss = 1.96304989\n",
            "epoch 2: \n",
            "w1 = tensor([[0.1284, 0.5317, 0.5425],\n",
            "        [0.1738, 0.2152, 0.2183]], requires_grad=True)\n",
            " w2 = tensor([[0.2250, 0.5626, 0.1619],\n",
            "        [0.3849, 0.2350, 0.9862],\n",
            "        [0.4336, 0.8439, 0.7710]], requires_grad=True)\n",
            " w3 = tensor([[0.8367, 0.9646],\n",
            "        [0.5786, 0.0356],\n",
            "        [0.5970, 0.0524]], requires_grad=True)\n",
            " w4 = tensor([[0.6990],\n",
            "        [0.8743]], requires_grad=True), loss = 1.82733953\n",
            "epoch 3: \n",
            "w1 = tensor([[0.1241, 0.5255, 0.5350],\n",
            "        [0.1674, 0.2030, 0.2036]], requires_grad=True)\n",
            " w2 = tensor([[0.2213, 0.5615, 0.1607],\n",
            "        [0.3773, 0.2327, 0.9838],\n",
            "        [0.4259, 0.8415, 0.7685]], requires_grad=True)\n",
            " w3 = tensor([[0.8333, 0.9602],\n",
            "        [0.5735, 0.0292],\n",
            "        [0.5902, 0.0438]], requires_grad=True)\n",
            " w4 = tensor([[0.6848],\n",
            "        [0.8687]], requires_grad=True), loss = 1.70551395\n",
            "epoch 4: \n",
            "w1 = tensor([[0.1201, 0.5197, 0.5279],\n",
            "        [0.1613, 0.1914, 0.1895]], requires_grad=True)\n",
            " w2 = tensor([[0.2179, 0.5605, 0.1596],\n",
            "        [0.3701, 0.2306, 0.9815],\n",
            "        [0.4186, 0.8394, 0.7662]], requires_grad=True)\n",
            " w3 = tensor([[0.8300, 0.9562],\n",
            "        [0.5688, 0.0232],\n",
            "        [0.5837, 0.0357]], requires_grad=True)\n",
            " w4 = tensor([[0.6714],\n",
            "        [0.8636]], requires_grad=True), loss = 1.59596145\n",
            "epoch 5: \n",
            "w1 = tensor([[0.1162, 0.5141, 0.5211],\n",
            "        [0.1555, 0.1803, 0.1760]], requires_grad=True)\n",
            " w2 = tensor([[0.2146, 0.5595, 0.1586],\n",
            "        [0.3633, 0.2286, 0.9794],\n",
            "        [0.4117, 0.8374, 0.7641]], requires_grad=True)\n",
            " w3 = tensor([[0.8271, 0.9524],\n",
            "        [0.5643, 0.0175],\n",
            "        [0.5777, 0.0279]], requires_grad=True)\n",
            " w4 = tensor([[0.6587],\n",
            "        [0.8589]], requires_grad=True), loss = 1.49731314\n",
            "epoch 6: \n",
            "w1 = tensor([[0.1124, 0.5087, 0.5146],\n",
            "        [0.1499, 0.1697, 0.1630]], requires_grad=True)\n",
            " w2 = tensor([[0.2115, 0.5586, 0.1577],\n",
            "        [0.3568, 0.2267, 0.9775],\n",
            "        [0.4053, 0.8356, 0.7622]], requires_grad=True)\n",
            " w3 = tensor([[0.8243, 0.9488],\n",
            "        [0.5601, 0.0120],\n",
            "        [0.5720, 0.0205]], requires_grad=True)\n",
            " w4 = tensor([[0.6467],\n",
            "        [0.8546]], requires_grad=True), loss = 1.40840161\n",
            "epoch 7: \n",
            "w1 = tensor([[0.1089, 0.5037, 0.5085],\n",
            "        [0.1445, 0.1595, 0.1506]], requires_grad=True)\n",
            " w2 = tensor([[0.2085, 0.5578, 0.1569],\n",
            "        [0.3507, 0.2250, 0.9757],\n",
            "        [0.3992, 0.8339, 0.7604]], requires_grad=True)\n",
            " w3 = tensor([[0.8218, 0.9454],\n",
            "        [0.5562, 0.0069],\n",
            "        [0.5666, 0.0134]], requires_grad=True)\n",
            " w4 = tensor([[0.6353],\n",
            "        [0.8506]], requires_grad=True), loss = 1.32820237\n",
            "epoch 8: \n",
            "w1 = tensor([[0.1054, 0.4989, 0.5026],\n",
            "        [0.1394, 0.1497, 0.1386]], requires_grad=True)\n",
            " w2 = tensor([[0.2058, 0.5571, 0.1561],\n",
            "        [0.3449, 0.2235, 0.9741],\n",
            "        [0.3935, 0.8323, 0.7588]], requires_grad=True)\n",
            " w3 = tensor([[0.8195, 0.9423],\n",
            "        [0.5526, 0.0020],\n",
            "        [0.5616, 0.0067]], requires_grad=True)\n",
            " w4 = tensor([[0.6246],\n",
            "        [0.8470]], requires_grad=True), loss = 1.25583076\n",
            "epoch 9: \n",
            "w1 = tensor([[0.1022, 0.4943, 0.4969],\n",
            "        [0.1344, 0.1404, 0.1272]], requires_grad=True)\n",
            " w2 = tensor([[0.2031, 0.5564, 0.1554],\n",
            "        [0.3394, 0.2220, 0.9726],\n",
            "        [0.3881, 0.8309, 0.7573]], requires_grad=True)\n",
            " w3 = tensor([[ 8.1728e-01,  9.3934e-01],\n",
            "        [ 5.4917e-01, -2.6393e-03],\n",
            "        [ 5.5693e-01,  3.1687e-04]], requires_grad=True)\n",
            " w4 = tensor([[0.6145],\n",
            "        [0.8436]], requires_grad=True), loss = 1.19049895\n",
            "epoch 10: \n",
            "w1 = tensor([[0.0990, 0.4899, 0.4916],\n",
            "        [0.1297, 0.1314, 0.1162]], requires_grad=True)\n",
            " w2 = tensor([[0.2007, 0.5557, 0.1547],\n",
            "        [0.3341, 0.2206, 0.9712],\n",
            "        [0.3830, 0.8296, 0.7560]], requires_grad=True)\n",
            " w3 = tensor([[ 0.8153,  0.9366],\n",
            "        [ 0.5460, -0.0070],\n",
            "        [ 0.5525, -0.0057]], requires_grad=True)\n",
            " w4 = tensor([[0.6050],\n",
            "        [0.8406]], requires_grad=True), loss = 1.13150966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader"
      ],
      "metadata": {
        "id": "2m2zDeuz0N9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "USvsCyYF0vr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScoreDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18]]) # 6x3\n",
        "    self.y = torch.tensor([[1],[0],[1],[1],[1],[0]]) # 6x1\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.size(0)"
      ],
      "metadata": {
        "id": "23Bt3cRJ0Py4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_dataset = ScoreDataset()"
      ],
      "metadata": {
        "id": "zAb8G6eP162U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(score_dataset.x)\n",
        "print(score_dataset.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzVKiN9C1_BB",
        "outputId": "429629d3-0cd0-468d-b64c-91fe2192f7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12],\n",
            "        [13, 14, 15],\n",
            "        [16, 17, 18]])\n",
            "tensor([[1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataLoader = DataLoader(dataset=score_dataset,batch_size=2,shuffle=True)"
      ],
      "metadata": {
        "id": "ezNQlDes2PPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(dataLoader):\n",
        "  print(f\"{i}: x={x}, y={y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qOE1IjH2cAJ",
        "outputId": "0c1e0b90-beb7-42c7-a593-c14e95eca518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: x=tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]]), y=tensor([[1],\n",
            "        [1]])\n",
            "1: x=tensor([[4, 5, 6],\n",
            "        [1, 2, 3]]), y=tensor([[0],\n",
            "        [1]])\n",
            "2: x=tensor([[13, 14, 15],\n",
            "        [16, 17, 18]]), y=tensor([[1],\n",
            "        [0]])\n"
          ]
        }
      ]
    }
  ]
}